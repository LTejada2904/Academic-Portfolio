{"cells":[{"cell_type":"markdown","metadata":{"id":"uOLwiH93h5w8"},"source":["# Importación de Librerías\n","En esta sección se importarán todas las librerías necesarias para correr el código."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wqLKRvgKhrFh"},"outputs":[],"source":["# Importación de Librerías\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import torch\n","\n","import sys\n","import itertools\n","import os\n","import re\n","import time as t\n","import math\n","import logging\n","import pickle\n","from datetime import datetime\n","from collections import OrderedDict\n","from tqdm import tqdm\n","from copy import deepcopy\n","\n","from tabulate import tabulate\n","\n","from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from sklearn.model_selection import KFold, train_test_split\n","\n","from imblearn.over_sampling import BorderlineSMOTE\n","\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.profiler\n","\n","!pip install torch_pruning\n","import torch_pruning as tp\n","\n","!pip install ptflops\n","from ptflops import get_model_complexity_info\n","\n","!pip install timm\n","from timm.data import resolve_data_config, create_loader\n","\n","!pip install apex\n","\n","try:\n","    from apex import amp\n","    from apex.parallel import DistributedDataParallel as DDP\n","    from apex.parallel import convert_syncbn_model\n","    from apex.parallel.optimized_sync_batchnorm import SyncBatchNorm\n","    has_apex = True\n","except ImportError:\n","    from torch.nn.parallel import DistributedDataParallel as DDP\n","    from torch.nn import SyncBatchNorm\n","    has_apex = False"]},{"cell_type":"markdown","metadata":{"id":"BdzLfbxki4Qb"},"source":["# Diseño estructural de funciones\n","En esta sección se diseñarán todas las funciones necesarias para el programa, incluyendo la arquitectura de preprocesamiento _________________"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oi1oz5hHi4ex"},"outputs":[],"source":["# Función para cargar los datos\n","def datos(ruta_x, ruta_y):\n","    X = pd.read_csv(ruta_x, header=None)\n","    y = pd.read_csv(ruta_y, header=None)\n","    return X, y\n","\n","# Función para concatenar DataFrames\n","def concat(df_2=None, df_1=None):\n","    if df_2 is None:\n","        return df_1\n","    elif df_1 is None:\n","        return df_2\n","    else:\n","        return pd.concat([df_2, df_1])\n","\n","# Función para aplicar BorderlineSMOTE\n","def smote(X, y):\n","    smote = BorderlineSMOTE()\n","    X_resampled, y_resampled = smote.fit_resample(X, y)\n","    return X_resampled, y_resampled\n","\n","# Función para graficar los resultados de SMOTE\n","def graph_smote(y, y_smote):\n","    state_labels = {0: 'W', 1: 'N1', 2: 'N2', 3: 'N3', 4: 'R'}\n","\n","    df = pd.DataFrame(columns=['Original', 'Improved'])\n","\n","    for i in range(5):\n","        original_count = y.value_counts().get(i, 0)\n","        improved_count = y_smote.value_counts().get(i, 0)\n","        total_original = len(y)\n","        total_improved = len(y_smote)\n","\n","        original_percentage = (original_count / total_original) * 100\n","        improved_percentage = (improved_count / total_improved) * 100\n","\n","        df.loc[state_labels[i]] = [original_percentage, improved_percentage]\n","\n","    ax = df.plot(kind='bar', color=['lightcoral', 'mediumpurple'], figsize=(10, 7))\n","    plt.xlabel('Sleep State')\n","    plt.ylabel('% of Dataset')\n","    plt.title(f'Class Balance Comparison')\n","    plt.legend(['Original', 'Improved'])\n","\n","    for p in ax.patches:\n","        ax.annotate(format(p.get_height(), '.1f') + '%',\n","                    (p.get_x() + p.get_width() / 2., p.get_height()),\n","                    ha = 'center',\n","                    va = 'center',\n","                    xytext = (0, 10),\n","                    textcoords = 'offset points')\n","\n","# Función para normalizar los datos\n","def norm(X):\n","    scaler = MinMaxScaler()\n","    X_norm = scaler.fit_transform(X)\n","    X_norm_df = pd.DataFrame(X_norm, index=X.index, columns=X.columns)\n","    return X_norm_df\n","\n","# Función para estandarizar los datos\n","def estd(X):\n","    scaler = StandardScaler()\n","    X_std = scaler.fit_transform(X)\n","    X_std_df = pd.DataFrame(X_std, index=X.index, columns=X.columns)\n","    return X_std_df\n","\n","# Función para obtener las dimensiones de entrada y número de clases\n","def dims_class(X, y):\n","    input_dims = X.shape[1]\n","    n_classes = len(y.iloc[:, 0].unique())\n","    return input_dims, n_classes\n","\n","# Función para búsqueda de mejores hiperparámetros\n","def hyperparameter_search(X, y, param_grid):\n","    input_dims, n_classes = dims_class(X, y)\n","    best_accuracy = 0.0\n","    best_params = None\n","\n","    keys = param_grid.keys()\n","    param_combinations = list(itertools.product(*param_grid.values()))\n","\n","    for params in param_combinations:\n","        param_dict = dict(zip(keys, params))\n","        print(f\"\\nEvaluando combinación de hiperparámetros: {param_dict}\")\n","\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","        X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).unsqueeze(1)\n","        y_train_tensor = torch.tensor(y_train.values, dtype=torch.long).squeeze()\n","        X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).unsqueeze(1)\n","        y_test_tensor = torch.tensor(y_test.values, dtype=torch.long).squeeze()\n","\n","        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","        train_loader = DataLoader(train_dataset, batch_size=param_dict['batch_size'], shuffle=True)\n","\n","        model_instance = DeepSleepNet(\n","            input_channels=1,\n","            n_rnn_layers=param_dict.get('n_rnn_layers', 2),\n","            dropout=param_dict.get('dropout', 0.5)\n","        )\n","\n","        if param_dict['optimizer'] == 'adam':\n","            optimizer = optim.Adam(model_instance.parameters(), lr=param_dict['learning_rate'])\n","        elif param_dict['optimizer'] == 'sgd':\n","            optimizer = optim.SGD(model_instance.parameters(), lr=param_dict['learning_rate'], momentum=param_dict.get('momentum', 0.0))\n","\n","        criterion = nn.CrossEntropyLoss()\n","\n","        start_time = t.time()\n","        model_instance.train()\n","        for epoch in range(param_dict['epochs']):\n","            running_loss = 0.0\n","            for X_batch, y_batch in train_loader:\n","                optimizer.zero_grad()\n","                outputs = model_instance(X_batch)\n","                loss = criterion(outputs, y_batch)\n","                loss.backward()\n","                optimizer.step()\n","                running_loss += loss.item()\n","            print(f\"Epoch {epoch+1}/{param_dict['epochs']}, Loss: {running_loss/len(train_loader)}\")\n","        end_time = t.time()\n","\n","        model_instance.eval()\n","        with torch.no_grad():\n","            y_pred = model_instance(X_test_tensor)\n","            _, y_pred_classes = torch.max(y_pred, 1)\n","        accuracy = accuracy_score(y_test, y_pred_classes.numpy())\n","\n","        total_time = end_time - start_time\n","\n","        print(f\"Accuracy: {accuracy:.4f}\")\n","        print(f\"Total Time: {total_time:.2f} seconds\")\n","\n","        if accuracy > best_accuracy:\n","            best_accuracy = accuracy\n","            best_params = param_dict\n","\n","    print(f\"\\nMejores Hiperparámetros: {best_params}\")\n","    print(f\"Mejor Precisión: {best_accuracy:.4f}\")\n","\n","    return best_params, best_accuracy\n","\n","# Función de entrenamiento\n","def train_model(model, X, y, X_val, y_val, epochs, batch_size, learning_rate, optimizer_type, momentum=0.0):\n","    X_tensor = torch.tensor(X.values, dtype=torch.float32).unsqueeze(1)\n","    y_tensor = torch.tensor(y.values, dtype=torch.long).squeeze()\n","    X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1)\n","    y_val_tensor = torch.tensor(y_val.values, dtype=torch.long).squeeze()\n","\n","    train_dataset = TensorDataset(X_tensor, y_tensor)\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","    if optimizer_type == 'adam':\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    elif optimizer_type == 'sgd':\n","        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n","\n","    criterion = nn.CrossEntropyLoss()\n","\n","    model.train()\n","    start_time = t.time()\n","    epoch_accuracies = []\n","    for epoch in range(epochs):\n","        running_loss = 0.0\n","        for X_batch, y_batch in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(X_batch)\n","            loss = criterion(outputs, y_batch)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        # Calcular precisión en el conjunto de validación\n","        model.eval()\n","        with torch.no_grad():\n","            y_pred = model(X_val_tensor)\n","            _, y_pred_classes = torch.max(y_pred, 1)\n","            accuracy = accuracy_score(y_val_tensor.numpy(), y_pred_classes.numpy())\n","            epoch_accuracies.append(accuracy)\n","            model.train()  # Regresar al modo de entrenamiento\n","\n","        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}, Accuracy: {accuracy:.4f}\")\n","\n","    end_time = t.time()\n","    training_time = end_time - start_time\n","    print(f\"Training Time: {training_time:.2f} seconds\")\n","\n","    return model, training_time, epoch_accuracies\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","def accuracy(X, y, model, param_dict, test_size=0.2):\n","\n","    # Split the dataset into training and validation sets\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=42)\n","\n","    # Usar directamente el modelo podado pasado como parámetro\n","    model_instance = model\n","\n","    # Imprimir detalles del modelo para verificar que es el modelo podado\n","    print(\"Inside accuracy function - model details:\")\n","    print(model_instance)\n","    print(\"Number of parameters inside accuracy function:\", count_parameters(model_instance))\n","\n","    # Timing the training process\n","    start_time = t.time()\n","    model_instance, training_time, epoch_accuracies = train_model(\n","        model_instance, X_train, y_train, X_val, y_val, param_dict['epochs'],\n","        param_dict['batch_size'], param_dict['learning_rate'],\n","        param_dict['optimizer'], param_dict.get('momentum', 0.0)\n","    )\n","    end_time = t.time()\n","    training_time = end_time - start_time\n","\n","    average_training_accuracy = np.mean(epoch_accuracies)\n","    print(f\"Training completed - Average Accuracy: {average_training_accuracy:.4f}, Training Time: {training_time:.2f} seconds\")\n","\n","    model_instance.eval()\n","    X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1)\n","    y_val_tensor = torch.tensor(y_val.values, dtype=torch.long).squeeze()\n","    with torch.no_grad():\n","        y_pred = model_instance(X_val_tensor)\n","        _, y_pred_classes = torch.max(y_pred, 1)\n","    validation_accuracy = accuracy_score(y_val, y_pred_classes.numpy())\n","\n","    print(f\"Validation Accuracy: {validation_accuracy:.4f}\")\n","\n","    # Calculate MACs, FLOPs, and parameters using ptflops\n","    macs, flops = get_model_complexity_info(model_instance, (1, X_val_tensor.size(2)), as_strings=False, print_per_layer_stat=False)\n","    total_params = count_parameters(model_instance)\n","\n","    print(f\"MACs: {macs}, FLOPs: {flops}, Parameters: {total_params}\")\n","\n","    metrics = {\n","        'training_accuracy': average_training_accuracy,\n","        'validation_accuracy': validation_accuracy,\n","        'training_time': training_time,\n","        'macs': macs,\n","        'flops': flops,\n","        'parameters': total_params\n","    }\n","\n","    return metrics\n","\n","#Función de cross validation\n","def cross_validation_accuracy(X, y, model, param_dict, folds=5):\n","    kf = KFold(n_splits=folds)\n","    total_accuracy = 0.0\n","    total_training_time = 0.0\n","    times_per_fold = []\n","    macs_per_fold = []\n","    flops_per_fold = []\n","    accuracies_per_fold = []\n","\n","    for fold, (train_index, val_index) in enumerate(kf.split(X), 1):\n","        print(f\"\\nFold {fold}/{folds}\")\n","\n","        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n","        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n","\n","        model_instance = DeepSleepNet(\n","            input_channels=1,\n","            n_rnn_layers=param_dict.get('n_rnn_layers', 2),\n","            dropout=param_dict.get('dropout', 0.5)\n","        )\n","\n","        # Timing the training process\n","        start_time = t.time()\n","        model_instance, training_time, epoch_accuracies = train_model(\n","            model_instance, X_train, y_train, X_val, y_val, param_dict['epochs'],\n","            param_dict['batch_size'], param_dict['learning_rate'],\n","            param_dict['optimizer'], param_dict.get('momentum', 0.0)\n","        )\n","        end_time = t.time()\n","        fold_training_time = end_time - start_time\n","        total_training_time += fold_training_time\n","        times_per_fold.append(fold_training_time)\n","\n","        fold_accuracy = np.mean(epoch_accuracies)\n","        print(f\"Fold {fold} - Average Accuracy: {fold_accuracy:.4f}, Training Time: {fold_training_time:.2f} seconds\")\n","\n","        model_instance.eval()\n","        X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32).unsqueeze(1)\n","        y_val_tensor = torch.tensor(y_val.values, dtype=torch.long).squeeze()\n","        with torch.no_grad():\n","            y_pred = model_instance(X_val_tensor)\n","            _, y_pred_classes = torch.max(y_pred, 1)\n","        accuracy = accuracy_score(y_val, y_pred_classes.numpy())\n","        total_accuracy += accuracy\n","        accuracies_per_fold.append(accuracy)\n","\n","        # Calculate MACs and FLOPs using ptflops\n","        macs, flops = get_model_complexity_info(model_instance, (1, X_val_tensor.size(2)), as_strings=False, print_per_layer_stat=False)\n","        macs_per_fold.append(macs)\n","        flops_per_fold.append(flops)\n","\n","    average_accuracy = total_accuracy / folds\n","    print(f\"\\nFinal Average Accuracy: {average_accuracy:.4f}\")\n","    print(f\"Total Training Time for all folds: {total_training_time:.2f} seconds\")\n","\n","    metrics = {\n","        'average_accuracy': average_accuracy,\n","        'total_training_time': total_training_time,\n","        'times_per_fold': times_per_fold,\n","        'macs_per_fold': macs_per_fold,\n","        'flops_per_fold': flops_per_fold,\n","        'accuracies_per_fold': accuracies_per_fold\n","    }\n","\n","    return metrics\n","\n","def compare_models(pruned_metrics, unpruned_metrics):\n","    # Print the metrics dictionaries for debugging\n","    print(\"Pruned Metrics:\", pruned_metrics)\n","    print(\"Unpruned Metrics:\", unpruned_metrics)\n","\n","    # Unpack the metrics\n","    pruned_training_accuracy = pruned_metrics['training_accuracy']\n","    pruned_validation_accuracy = pruned_metrics['validation_accuracy']\n","    pruned_training_time = pruned_metrics['training_time']\n","    pruned_macs = pruned_metrics['macs']\n","    pruned_flops = pruned_metrics['flops']\n","    pruned_parameters = pruned_metrics['parameters']\n","\n","    unpruned_training_accuracy = unpruned_metrics['training_accuracy']\n","    unpruned_validation_accuracy = unpruned_metrics['validation_accuracy']\n","    unpruned_training_time = unpruned_metrics['training_time']\n","    unpruned_macs = unpruned_metrics['macs']\n","    unpruned_flops = unpruned_metrics['flops']\n","    unpruned_parameters = unpruned_metrics['parameters']\n","\n","    # Create a comparison DataFrame\n","    comparison_df = pd.DataFrame({\n","        'Metric': ['Training Accuracy', 'Validation Accuracy', 'Training Time', 'MACs', 'FLOPs', 'Parameters'],\n","        'Pruned Model': [\n","            pruned_training_accuracy,\n","            pruned_validation_accuracy,\n","            pruned_training_time,\n","            pruned_macs,\n","            pruned_flops,\n","            pruned_parameters\n","        ],\n","        'Unpruned Model': [\n","            unpruned_training_accuracy,\n","            unpruned_validation_accuracy,\n","            unpruned_training_time,\n","            unpruned_macs,\n","            unpruned_flops,\n","            unpruned_parameters\n","        ]\n","    })\n","\n","    # Format values to avoid scientific notation\n","    def format_value(x):\n","        if isinstance(x, float):\n","            return f'{x:.6f}'\n","        elif isinstance(x, int):\n","            return f'{x:,}'\n","        else:\n","            return x\n","\n","    comparison_df = comparison_df.applymap(format_value)\n","\n","    return comparison_df\n"]},{"cell_type":"markdown","metadata":{"id":"i7PZGDv7Qd-Y"},"source":["# Creación de Modelo Clasificador\n","En esta sección se implementan las clases para el diseño de clasificador y se ejecuta el clasificador en los datos sin comprimir modelo.\n","\n","Artículo Publicado en: [Papers with Code](https://https://paperswithcode.com/).\n","\n","DeepSleepNet: a Model for Automatic Sleep Stage Scoring based on Raw Single-Channel EEG'\n","\n","Puede acceder al artículo y fuente de código en el siguiente [enlace](https://paperswithcode.com/paper/deepsleepnet-a-model-for-automatic-sleep).\n","\n","El clasificador fue modificado para su funcionamiento en PyTorch para implementar métodos de compresión en PyTorch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RgfijmftQjGd"},"outputs":[],"source":["class DeepFeatureNet(nn.Module):\n","    def __init__(self, input_channels):\n","        super(DeepFeatureNet, self).__init__()\n","        self.features_s = nn.Sequential(\n","            nn.Conv1d(input_channels, 64, 50, 6, padding=24),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool1d(kernel_size=8, stride=8, padding=4),\n","            nn.Dropout(),\n","            nn.Conv1d(64, 128, 6, padding=3),\n","            nn.BatchNorm1d(128),\n","            nn.Conv1d(128, 128, 6, padding=3),\n","            nn.BatchNorm1d(128),\n","            nn.Conv1d(128, 128, 6, padding=3),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=1),\n","        )\n","        self.features_l = nn.Sequential(\n","            nn.Conv1d(input_channels, 64, 400, 50, padding=200),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool1d(kernel_size=4, stride=4, padding=2),\n","            nn.Dropout(),\n","            nn.Conv1d(64, 128, 8, padding=3),\n","            nn.BatchNorm1d(128),\n","            nn.Conv1d(128, 128, 8, padding=3),\n","            nn.BatchNorm1d(128),\n","            nn.Conv1d(128, 128, 8, padding=3),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool1d(kernel_size=2, stride=2, padding=1),\n","        )\n","\n","    def forward(self, x):\n","        x_s = self.features_s(x)\n","        x_l = self.features_l(x)\n","        x = torch.cat((x_s, x_l), 2)\n","        x = x.view(x.size(0), -1, x.size(2))\n","        return x\n","\n","class DeepSleepNet(nn.Module):\n","    def __init__(self, input_channels, n_rnn_layers=2, dropout=0.5):\n","        super(DeepSleepNet, self).__init__()\n","        self.feature_extractor = DeepFeatureNet(input_channels)\n","\n","        # Calcular el tamaño de la salida del extractor de características\n","        dummy_input = torch.zeros(1, input_channels, 3000)\n","        dummy_output = self.feature_extractor(dummy_input)\n","        features_len = dummy_output.shape[2]  # Usar la longitud correcta para el LSTM\n","        lstm_input_size = dummy_output.shape[1]  # La dimensión de características para LSTM\n","\n","        self.features_seq = nn.LSTM(lstm_input_size, 512, batch_first=True, bidirectional=True, dropout=dropout, num_layers=n_rnn_layers)\n","        self.res = nn.Linear(512 * 2, 1024)  # 512 * 2 debido a bidireccionalidad\n","\n","    def forward(self, x):\n","        x = self.feature_extractor(x)\n","        x = x.transpose(1, 2)  # Transponer para que la dimensión de características sea la entrada del LSTM\n","        x_blstm, _ = self.features_seq(x)\n","        x_res = self.res(x_blstm[:, -1, :])  # Usar la última salida de LSTM\n","        x = torch.mul(x_res, x_blstm[:, -1, :])  # Multiplicar por la última salida de LSTM\n","        return x\n"]},{"cell_type":"markdown","metadata":{"id":"WOrlDvU4jp-B"},"source":["# Importación y Organización de Datos\n","En esta sección estaremos importando conjuntos de datos de sueño y estaremos uniéndolos para procesar una mayor cantidad de datos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q17s8LpujqFg"},"outputs":[],"source":["# Inicializamos df_X y df_y\n","df_X = None\n","df_y = None\n","\n","## Importamos los datos y concatenamos para que sea un Dataframe\n","#for i in range(6):\n","#    X, y = datos(f\"/content/drive/MyDrive/Investigacion/Dataset_1/SC_{i}.csv\", f\"/content/drive/MyDrive/Investigacion/Dataset_1/y_{i}.csv\")\n","#    df_X = concat(df_X, X)\n","#    df_y = concat(df_y, y)\n","\n","for i in range(1):\n","    X, y = datos(f\"/content/drive/MyDrive/Investigacion/Dataset_1/SC_{i}.csv\", f\"/content/drive/MyDrive/Investigacion/Dataset_1/y_{i}.csv\")\n","    df_X = concat(df_X, X)\n","    df_y = concat(df_y, y)\n"]},{"cell_type":"markdown","metadata":{"id":"C0L5vVu6qO7a"},"source":["# Preprocesamiento de Datos\n","En esta sección estaremos preprocesando los datos con BorderlineSmote, Estandarización y Normalización."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vkgd3NgiqPDy"},"outputs":[],"source":["# BorderlineSmote con Raw Data\n","X_smote, y_smote = smote(df_X, df_y)\n","graph_smote(df_y, y_smote)\n","\n","# BorderlineSmote con Standarized Data\n","X_std = estd(df_X)\n","X_std_smote, y_std_smote = smote(X_std, df_y)\n","\n","# BorderlineSmote con Normalized Data\n","X_norm = norm(df_X)\n","X_norm_smote, y_norm_smote = smote(X_norm, df_y)\n"]},{"cell_type":"markdown","source":["# Búsqueda de mejores Hiperparámetros\n","En esta sección, se creo una función de iteración de parámetros para hallar los mejores parámetros para la función."],"metadata":{"id":"sdNY9mZ4OpBl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-P5XP37JLwfz"},"outputs":[],"source":["# Búsqueda de mejores hiperparámetros\n","param_grid = {\n","    'epochs': [25, 50, 100],\n","    'batch_size': [100, 500, 1000],\n","    'learning_rate': [0.0001, 0.001, 0.01],\n","    'optimizer': ['adam', 'sgd']\n","}\n","\n","best_params, best_accuracy = hyperparameter_search(X_smote, y_smote, param_grid)\n","best_params_std, best_accuracy_std = hyperparameter_search(X_std_smote, y_std_smote, param_grid)\n","best_params_norm, best_accuracy_norm = hyperparameter_search(X_norm_smote, y_norm_smote, param_grid)\n"]},{"cell_type":"markdown","metadata":{"id":"DOTRcmWfzDkO"},"source":["# Implementación de Clasificador sin Poda\n","En esta sección se aplica y entrena el modelo de clasificación con los mejores hiperparámetros hallados para el modelo de deep learning.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fBtCR3KG0Ard"},"outputs":[],"source":["# Definir el diccionario de hiperparámetros\n","param_dict = {\n","    'epochs': 10,\n","    'batch_size': 1000,\n","    'learning_rate': 0.001,\n","    'optimizer': 'adam',\n","    'n_rnn_layers': 2,\n","    'dropout': 0.5\n","}\n","\n","# Crear el modelo\n","model = DeepSleepNet(\n","    input_channels=1,\n","    n_rnn_layers=param_dict['n_rnn_layers'],\n","    dropout=param_dict['dropout']\n",")\n","\n","\n","# Entrenar el modelo y calcular el accuracy sin validación cruzada\n","unpruned_metrics = accuracy(X_std_smote, y_std_smote, model, param_dict)\n"]},{"cell_type":"markdown","metadata":{"id":"jwHxxgbT7JLM"},"source":["# Creación del Modelo de Prunning\n","En esta sección veremos la definición de las clases de compresión creando un Modelo de Prunning ideal usando Slimming Pruner\n","\n","Artículo Publicado en: [Papers with Code](https://https://paperswithcode.com/).\n","\n","Prunning Filters For Efficient ConvNets\n","\n","Puede acceder al artículo y fuente de código en el siguiente [enlace](https://paperswithcode.com/sota/network-pruning-on-imagenet)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ADRUAnH7H5-"},"outputs":[],"source":["class MySlimmingPruner(tp.pruner.MetaPruner):\n","    def regularize(self, model, reg):\n","        for m in model.modules():\n","            if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)) and m.affine==True:\n","                m.weight.grad.data.add_(reg*torch.sign(m.weight.data)) # Lasso for sparsity\n","\n","class MySlimmingImportance(tp.importance.Importance):\n","    def __call__(self, group, **kwargs):\n","        group_imp = [] # (num_bns, num_channels)\n","        # 1. iterate the group to estimate importance\n","        for dep, idxs in group:\n","            layer = dep.target.module # get the target model\n","            prune_fn = dep.handler    # get the pruning function of target model, unused in example\n","            if isinstance(layer, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)) and layer.affine:\n","                local_imp = torch.abs(layer.weight.data)\n","                group_imp.append(local_imp)\n","        if len(group_imp)==0: return None # return None if the group contains no BN layer\n","        # 2. reduce your group importance to a 1-D scroe vector. Here we use the average score across layers.\n","        group_imp = torch.stack(group_imp, dim=0).mean(dim=0)\n","        return group_imp # (num_channels, )\n","\n","# You can implement any importance functions, as long as it transforms a group to a 1-D score vector.\n","class RandomImportance(tp.importance.Importance):\n","    @torch.no_grad()\n","    def __call__(self, group, **kwargs):\n","        _, idxs = group[0]\n","        return torch.rand(len(idxs))\n"]},{"cell_type":"markdown","metadata":{"id":"jJ3rI7ot2SqE"},"source":["# Implementación Modo de Poda ConvNets (DepGraphs)\n","En esta sección se implementan la clases para el diseño de compresión y se ejecuta en el clasificador antes de entrenar.\n","\n"]},{"cell_type":"markdown","source":["1.   features_s[0]: Conv1d(1, 64, kernel_size=(50,), stride=(6,), padding=(24,))\n","2.   features_s[5]: Conv1d(64, 128, kernel_size=(6,), stride=(1,), padding=(3,))\n","3.   features_s[7]: Conv1d(128, 128, kernel_size=(6,), stride=(1,), padding(3,))\n","4.   features_s[9]: Conv1d(128, 128, kernel_size=(6,), stride=(1,), padding(3,))\n","5.   features_l[0]: Conv1d(1, 64, kernel_size=(400,), stride=(50,), paddi(200,))\n","6.   features_l[5]: Conv1d(64, 128, kernel_size=(8,), stride=(1,), padding=(3,))\n","7.   features_l[7]: Conv1d(128, 128, kernel_size=(8,), stride=(1,), padding(3,))\n","8.   features_l[9]: Conv1d(128, 128, kernel_size=(8,), stride=(1,), padding(3,))\n","\n","\n","\n"],"metadata":{"id":"flH_24CwFViw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJ09m6UCATaa"},"outputs":[],"source":["# Crear el modelo\n","model = DeepSleepNet(\n","    input_channels=1,\n","    n_rnn_layers=param_dict['n_rnn_layers'],\n","    dropout=param_dict['dropout']\n",")\n","\n","# Convertir los datos a tensores de PyTorch\n","input_dims, n_classes = dims_class(X_smote, y_smote)\n","X_smote_tensor = torch.tensor(X_smote.values, dtype=torch.float32).view(-1, 1, input_dims)\n","\n","# Usar un subconjunto de los datos como ejemplos de entrada para la poda\n","example_inputs = X_smote_tensor[:64]\n","\n","# Imprimir el modelo antes de la poda\n","print(\"Before pruning:\")\n","print(model)\n","\n","# Contar los parámetros antes de la poda\n","print(\"Parameters before pruning:\", count_parameters(model))\n","\n","# Construir el grafo de dependencias para DeepSleepNet\n","DG = tp.DependencyGraph().build_dependency(model, example_inputs=example_inputs)\n","\n","# Seleccionar canales para podar más agresivamente de múltiples capas\n","pruning_ratios = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]  # Podar 50% de los canales\n","layers_to_prune = [\n","    model.feature_extractor.features_s[0],  # Conv1\n","    model.feature_extractor.features_s[5],  # Conv2\n","    model.feature_extractor.features_s[7],  # Conv3\n","    model.feature_extractor.features_s[9],  # Conv4\n","\n","    model.feature_extractor.features_l[0],  # Conv5\n","    model.feature_extractor.features_l[5],  # Conv6\n","    model.feature_extractor.features_l[7],  # Conv7\n","    model.feature_extractor.features_l[9],  # Conv8\n","]\n","\n","for layer, ratio in zip(layers_to_prune, pruning_ratios):\n","    num_channels = layer.out_channels\n","    pruning_idxs = list(range(0, num_channels, int(1/ratio)))\n","    print(f\"Pruning indices for layer {layer}: {pruning_idxs}\")  # Verificación de índices de poda\n","    pruning_group = DG.get_pruning_group(layer, tp.prune_conv_out_channels, idxs=pruning_idxs)\n","    if DG.check_pruning_group(pruning_group):\n","        pruning_group.prune()\n","    else:\n","        print(f\"Skipping pruning for layer {layer} due to dependency check failure.\")\n","\n","# Imprimir el modelo después de la poda\n","print(\"After pruning:\")\n","print(model)\n","\n","# Contar los parámetros después de la poda\n","print(\"Parameters after pruning:\", count_parameters(model))\n","\n","# Entrenar el modelo y calcular el accuracy sin validación cruzada\n","pruned_metrics_CN = accuracy(X_std_smote, y_std_smote, model, param_dict)\n"]},{"cell_type":"code","source":["# Imprimir resultados\n","comparison_df = compare_models(pruned_metrics_CN, unpruned_metrics)\n","print(comparison_df)\n"],"metadata":{"id":"SpXpGkIveiNp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Knapsack\n","Corrido el modelo de knapsack con el modelo de DeepSleep\n","\n","[github](https://github.com/yoniaflalo/knapsack_pruning)"],"metadata":{"id":"GL5z2jhEzsyo"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class KnapsackPruning:\n","    def __init__(self, model, data_config, loader, args, use_amp=False):\n","        self.model = model\n","        self.data_config = data_config\n","        self.loader = loader\n","        self.args = args\n","        self.use_amp = use_amp\n","        self.new_net = None\n","\n","    def compute_num_channels_per_layer_taylor(self):\n","        list_channel_to_prune = []\n","        for name, module in self.model.named_modules():\n","            if isinstance(module, nn.Conv1d):\n","                importance_scores = torch.rand(module.out_channels)  # Placeholder for importance score calculation\n","                num_channels_to_prune = int(module.out_channels * self.args.pruning_ratio)\n","                channels_to_prune = importance_scores.topk(num_channels_to_prune, largest=False)[1]\n","                list_channel_to_prune.append((name, channels_to_prune))\n","        return list_channel_to_prune\n","\n","    def prune_batchnorm(self, batchnorm_layer, mask):\n","        num_features_to_keep = mask.sum().item()\n","\n","        print(f\"Pruning BatchNorm1d: {batchnorm_layer}\")\n","        print(f\"Original running_mean shape: {batchnorm_layer.running_mean.shape}, running_var shape: {batchnorm_layer.running_var.shape}\")\n","        print(f\"Mask: {mask}\")\n","\n","        bn = nn.BatchNorm1d(num_features_to_keep).to(batchnorm_layer.weight.device)\n","\n","        bn.weight.data = batchnorm_layer.weight.data[mask].clone()\n","        bn.bias.data = batchnorm_layer.bias.data[mask].clone()\n","        bn.running_mean = batchnorm_layer.running_mean[mask].clone()\n","        bn.running_var = batchnorm_layer.running_var[mask].clone()\n","\n","        print(f\"New BatchNorm1d layer: {bn}\")\n","        print(f\"New running_mean shape: {bn.running_mean.shape}, running_var shape: {bn.running_var.shape}\")\n","\n","        return bn\n","\n","    def prune_conv1d_layer(self, layer, channels_to_prune):\n","        mask = torch.ones(layer.out_channels, dtype=torch.bool)\n","        mask[channels_to_prune] = False\n","\n","        new_out_channels = mask.sum().item()\n","\n","        print(f\"Pruning Conv1d: {layer}\")\n","        print(f\"Original weight shape: {layer.weight.shape}\")\n","        if layer.bias is not None:\n","            print(f\"Original bias shape: {layer.bias.shape}\")\n","\n","        new_conv = nn.Conv1d(\n","            in_channels=layer.in_channels,\n","            out_channels=new_out_channels,\n","            kernel_size=layer.kernel_size,\n","            stride=layer.stride,\n","            padding=layer.padding,\n","            bias=layer.bias is not None\n","        )\n","\n","        new_conv.weight.data = layer.weight.data[mask].clone()\n","        if layer.bias is not None:\n","            new_conv.bias.data = layer.bias.data[mask].clone()\n","\n","        print(f\"New Conv1d layer: {new_conv}\")\n","        print(f\"New weight shape: {new_conv.weight.shape}\")\n","        if new_conv.bias is not None:\n","            print(f\"New bias shape: {new_conv.bias.shape}\")\n","\n","        # Return the mask for BatchNorm layer pruning\n","        return new_conv, mask\n","\n","    def apply_pruning(self, layers, list_channel_to_prune, prefix):\n","        new_layers = []\n","        previous_mask = None\n","        for name, module in layers.named_children():\n","            full_name = f\"{prefix}.{name}\"\n","            if isinstance(module, nn.Conv1d):\n","                channels_to_prune = next((channels for lname, channels in list_channel_to_prune if lname == full_name), None)\n","                if channels_to_prune is not None:\n","                    new_conv, mask = self.prune_conv1d_layer(module, channels_to_prune)\n","                    new_layers.append((name, new_conv))\n","                    previous_mask = mask\n","                else:\n","                    new_layers.append((name, module))\n","                    previous_mask = None\n","            elif isinstance(module, nn.BatchNorm1d) and previous_mask is not None:\n","                # Adjust the mask to the number of features in the BatchNorm layer\n","                print(f\"Pruning BatchNorm1d for {full_name} with previous mask {previous_mask}\")\n","                previous_mask = previous_mask[:module.num_features]\n","                new_bn = self.prune_batchnorm(module, previous_mask)\n","                new_layers.append((name, new_bn))\n","                previous_mask = None\n","            else:\n","                new_layers.append((name, module))\n","                previous_mask = None\n","\n","        # Debugging: Check consistency of layers\n","        for i, (name, module) in enumerate(new_layers):\n","            if isinstance(module, nn.Conv1d):\n","                print(f\"Layer {i} ({name}) is Conv1d with {module.out_channels} out_channels\")\n","            elif isinstance(module, nn.BatchNorm1d):\n","                print(f\"Layer {i} ({name}) is BatchNorm1d with {module.num_features} features\")\n","\n","        return nn.Sequential(*[module for name, module in new_layers])\n","\n","    def redesign_module_deepfeature(self, list_channel_to_prune):\n","        self.model.feature_extractor.features_s = self.apply_pruning(\n","            self.model.feature_extractor.features_s,\n","            list_channel_to_prune,\n","            \"feature_extractor.features_s\"\n","        )\n","        self.model.feature_extractor.features_l = self.apply_pruning(\n","            self.model.feature_extractor.features_l,\n","            list_channel_to_prune,\n","            \"feature_extractor.features_l\"\n","        )\n","\n","    def prune_model(self):\n","        list_channel_to_prune = self.compute_num_channels_per_layer_taylor()\n","        self.redesign_module_deepfeature(list_channel_to_prune)\n","\n","        self.model.train()\n","        if isinstance(self.model, nn.DataParallel) or isinstance(self.model, nn.parallel.DistributedDataParallel):\n","            self.model = self.model.module\n","        else:\n","            self.model = self.model.cuda()\n","\n","        optimizer = self.create_optimizer(self.model)\n","\n","        return self.model, optimizer\n","\n","    def create_optimizer(self, model):\n","        optimizer = torch.optim.Adam(model.parameters(), lr=self.args.lr)\n","        return optimizer\n"],"metadata":{"id":"2F2Xsa2LAiGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import argparse\n","\n","# Example setup for arguments, data_config, and loader\n","data_config = None  # This should be your actual data configuration\n","loader = None  # This should be your actual data loader\n","args = argparse.Namespace(\n","    pruning_ratio=0.2,  # Example pruning ratio (20%)\n","    lr=0.001,            # Example learning rate for the optimizer\n","    batch_size=1000,      # Example batch size\n","    batch_size_prune=1000,  # Example pruning batch size\n","    use_time=False,     # Example flag for using timing in pruning\n",")  # Replace with actual arguments as needed\n","\n","# Initialize the pruning class with your model\n","knapsack_pruning = KnapsackPruning(model, data_config, loader, args)\n","\n","# Prune the model\n","pruned_model, optimizer = knapsack_pruning.prune_model()\n","\n","device = torch.device(\"cpu\")\n","pruned_model.to(device)\n","\n","# Evaluate the pruned model\n","# Assuming you have a function `accuracy` that takes input data, labels, and the model to compute accuracy\n","pruned_metrics_KS = accuracy(X_std_smote, y_std_smote, pruned_model, param_dict)\n","\n","# Print the pruned model's metrics\n","print(\"Pruned Model Metrics:\")\n","print(pruned_metrics_KS)\n"],"metadata":{"id":"AJpFRmRsB4ki"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}